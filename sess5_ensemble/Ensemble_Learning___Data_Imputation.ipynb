{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble_Learning_&_Data_Imputation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soNvelIHjYnv",
        "colab_type": "text"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5x8J3PtjjWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw2dwxmyiw1n",
        "colab_type": "text"
      },
      "source": [
        "# **Missing Data Imputation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmohLCFEiOkp",
        "colab_type": "text"
      },
      "source": [
        "### Define a function for drawing scatter plots of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odVVpc6OiVmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DrawScatterPlot2D(data, label, fig, title):\n",
        "    color = np.array(['red' if label[i] == 0 else 'black' for i in range(len(label))])\n",
        "    plt.figure(fig)\n",
        "    plt.scatter(data[:, 0], data[:, 1], s=50, c=color, alpha=1)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Feature 1')\n",
        "    plt.ylabel('Feature 2')\n",
        "    plt.show()\n",
        "    plt.close(fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNZuvWD3rTfn",
        "colab_type": "text"
      },
      "source": [
        "### Generate data with missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE-tv92kGxNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = 0\n",
        "N = 6\n",
        "randomSeed = 1\n",
        "class1 = np.array([np.random.RandomState(seed=randomSeed).normal(0, 1, N)*0.4 + 2, \n",
        "                   np.random.RandomState(seed=randomSeed+1).normal(0, 1, N)*0.4 + 5]).transpose()\n",
        "class2 = np.array([np.random.RandomState(seed=randomSeed+2).normal(0, 1, N)*0.4 + 5, \n",
        "                   np.random.RandomState(seed=randomSeed+3).normal(0, 1, N)*0.4 + 2]).transpose()\n",
        "data = np.vstack((class1, class2))\n",
        "label = np.vstack((np.zeros((N, 1)), np.ones((N, 1))))\n",
        "\n",
        "nanID = [3, 10]\n",
        "dataWithNan = data\n",
        "dataWithNan[nanID[0], 0] = np.nan\n",
        "dataWithNan[nanID[1], 1] = np.nan\n",
        "nonNanID = [0, 1, 2, 4, 5, 6, 7, 8, 9, 11]\n",
        "print(data)\n",
        "fig = fig + 1\n",
        "DrawScatterPlot2D(dataWithNan, label, fig, 'Data with missing values')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jJQu4w5l_vI",
        "colab_type": "text"
      },
      "source": [
        "### Impute by mean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lNGnFFpiwaA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imp = SimpleImputer(strategy='mean')\n",
        "dataImpute = imp.fit_transform(dataWithNan)\n",
        "fig = fig + 1\n",
        "DrawScatterPlot2D(dataImpute, label, fig, 'Imputation by Mean')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl0iufbSmqVT",
        "colab_type": "text"
      },
      "source": [
        "### Impute by median"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xowB3jeapur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imp = SimpleImputer(strategy='median')\n",
        "dataImpute = imp.fit_transform(dataWithNan)\n",
        "fig = fig + 1\n",
        "DrawScatterPlot2D(dataImpute, label, fig, 'Imputation by Median')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKx5W5JBnE8Z",
        "colab_type": "text"
      },
      "source": [
        "### Define a function for imputation using K nearest neighbors (KNN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8u8MJsFnjCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def KNN_Impute(data, k = 3):\n",
        "    import copy\n",
        "    dataImpute = copy.deepcopy(data)\n",
        "\n",
        "    numS = data.shape[0]\n",
        "    dist = np.empty((numS, numS))\n",
        "    dist.fill(np.nan)\n",
        "\n",
        "    for i in range(numS-1):\n",
        "        for j in range(i+1, numS):\n",
        "            nnID = np.intersect1d(np.where(np.invert(np.isnan(data[i, :])))[0], \n",
        "                                  np.where(np.invert(np.isnan(data[j, :])))[0])\n",
        "            if len(nnID) > 0:\n",
        "                dist[i, j] = np.sqrt(np.mean((data[i, nnID] - data[j, nnID]) ** 2))\n",
        "                dist[j, i] = dist[i, j]\n",
        "\n",
        "    for i in range(numS):\n",
        "        nID = np.where(np.isnan(data[i, :]))[0]\n",
        "        if len(nID) == 0:\n",
        "            continue\n",
        "        nnDistID = np.where(np.invert(np.isnan(dist[i, :])))[0]\n",
        "        sortedID = nnDistID[np.argsort(dist[i, nnDistID])]\n",
        "        for j in range(len(nID)):\n",
        "            nnIDj = np.where(np.invert(np.isnan(data[:, nID[j]])))[0]\n",
        "            sortedIDj = sortedID[np.sort(np.where(np.isin(sortedID, nnIDj))[0])]\n",
        "            if len(sortedIDj) > k:\n",
        "                sortedIDj = sortedIDj[:k]\n",
        "            if len(sortedIDj) > 0:\n",
        "                dataImpute[i, nID[j]] = np.mean(data[sortedIDj, nID[j]])\n",
        "\n",
        "    return dataImpute"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmAzI3KMn6DS",
        "colab_type": "text"
      },
      "source": [
        "### Impute using KNN approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1CZTJ8Un6oW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataImpute = KNN_Impute(dataWithNan, k=3)\n",
        "fig = fig + 1\n",
        "DrawScatterPlot2D(dataImpute, label, fig, 'Imputation using KNN')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmT5kbUqsIic",
        "colab_type": "text"
      },
      "source": [
        "# Imbalanced Data Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMmSGQ8VsS7N",
        "colab_type": "text"
      },
      "source": [
        "### Define a function for logistic regression classification and visualization in 2D space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L95WBWB-sxos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LogisticRegression2D(trainData, trainLabel, testData, testLabel, fig=1, \n",
        "                         randomSeed=1, classWeight=None):\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "    model = LogisticRegression(random_state=randomSeed, solver='lbfgs', \n",
        "                               class_weight=classWeight)\n",
        "    model.fit(trainData, trainLabel)\n",
        "    pred = model.predict(testData)\n",
        "    sensitivity = np.round(np.sum(pred[np.where(testLabel == 1)[0]] == 1) / \n",
        "                           np.sum(testLabel == 1), 3)\n",
        "    specificity = np.round(np.sum(pred[np.where(testLabel == 0)[0]] == 0) / \n",
        "                           np.sum(testLabel == 0), 3)\n",
        "    accuracy = np.round(np.sum(pred == testLabel) / len(testLabel), 3)\n",
        "\n",
        "    x = np.linspace(np.min(testData[:, 0]), np.max(testData[:, 0]), 100)\n",
        "    y = -model.intercept_ / model.coef_[0, 1] - model.coef_[0, 0] / model.coef_[0, 1] * x\n",
        "    idK = np.intersect1d(np.where(y >= np.min(testData[:, 1]))[0], \n",
        "                         np.where(y <= np.max(testData[:, 1]))[0])\n",
        "    idK = np.sort(idK)\n",
        "    x = x[idK]\n",
        "    y = y[idK]\n",
        "    testColor = np.array(['red' if testLabel[i] == 0 else 'blue' for i in \n",
        "                          range(len(testLabel))])\n",
        "\n",
        "    plt.figure(fig)\n",
        "    plt.scatter(testData[:, 0], testData[:, 1], s=2, c=testColor, alpha=1)\n",
        "    plt.plot(x, y, '-g', linewidth=2)\n",
        "    plt.title('Sensitivity = ' + str(sensitivity) + ', Specificity = ' + \n",
        "              str(specificity) + ', Accuracy = ' + str(accuracy))\n",
        "    plt.xlabel('Feature 1')\n",
        "    plt.ylabel('Feature 2')\n",
        "    plt.show()\n",
        "    plt.close(fig)    \n",
        "\n",
        "    return\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZOOy4t7uHsD",
        "colab_type": "text"
      },
      "source": [
        "### Generate 2D toy data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRRwN4pHuSki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N1 = 3000 # Number of samples in majority class\n",
        "N2 = 300 # Number of samples in minority class\n",
        "fig = 0\n",
        "randomSeed = 1\n",
        "transM = np.array([[-0.3, 1.3], [1.3, -0.3]])\n",
        "numFold = 3 # Number of data folds for cross-validation\n",
        "numS = N1 + N2 # Total number of samples\n",
        "class1 = np.array([np.random.RandomState(seed=randomSeed).normal(3, 3, N1), \n",
        "                   np.random.RandomState(seed=randomSeed+1).normal(3, 3, N1)]).transpose()\n",
        "class1 = np.matmul(class1, transM)\n",
        "class2 = np.array([np.random.RandomState(seed=randomSeed+2).normal(0, 2, N2), \n",
        "                   np.random.RandomState(seed=randomSeed+3).normal(0, 2, N2)]).transpose()\n",
        "class2 = np.matmul(class2, transM)\n",
        "data = np.vstack((class1, class2))\n",
        "label = np.concatenate((np.zeros(N1), np.ones(N2)))\n",
        "color = np.array(['red' if label[i] == 0 else 'blue' for i in range(len(label))])\n",
        "\n",
        "fig = fig + 1\n",
        "plt.figure(fig)\n",
        "plt.scatter(data[:, 0], data[:, 1], s=2, c=color, alpha=1)\n",
        "plt.title('Whole dataset')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.show()\n",
        "plt.close(fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A2QcBY_wEYm",
        "colab_type": "text"
      },
      "source": [
        "### Partition data into training set and testing set, and do classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE4nWaKRwaYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "randID = np.random.RandomState(seed=randomSeed).permutation(numS)\n",
        "trainID = randID[:int(numS*(numFold-1)/numFold)]\n",
        "testID = randID[int(numS*(numFold-1)/numFold):]\n",
        "trainData = data[trainID, :]\n",
        "trainLabel = label[trainID]\n",
        "testData = data[testID, :]\n",
        "testLabel = label[testID]\n",
        "\n",
        "fig = fig + 1\n",
        "LogisticRegression2D(trainData, trainLabel, testData, testLabel, fig, randomSeed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "799PLUtY1mU-",
        "colab_type": "text"
      },
      "source": [
        "### Random under-sampling of majority class for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x281AFT211iY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "sampler = RandomUnderSampler(random_state=randomSeed)\n",
        "trainData2, trainLabel2 = sampler.fit_resample(trainData, trainLabel)\n",
        "fig = fig + 1\n",
        "LogisticRegression2D(trainData2, trainLabel2, testData, testLabel, fig, randomSeed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_94tQX02lEE",
        "colab_type": "text"
      },
      "source": [
        "### Under-sampling of majority class using K-means clustering for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ck2B7tHS3AkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "class1ID = np.where(trainLabel == 0)[0]\n",
        "class2ID = np.where(trainLabel == 1)[0]\n",
        "trainDataClass1 = trainData[class1ID, :]\n",
        "trainLabelClass1 = trainLabel[class1ID]\n",
        "trainDataClass2 = trainData[class2ID, :]\n",
        "trainLabelClass2 = trainLabel[class2ID]\n",
        "kmeans = KMeans(n_clusters=len(trainLabelClass2), random_state=randomSeed).fit(trainDataClass1)\n",
        "uniqueLabel, index = np.unique(kmeans.labels_, return_index=True)\n",
        "trainData2 = np.vstack((trainDataClass1[index, :], trainDataClass2))\n",
        "trainLabel2 = np.concatenate((trainLabelClass1[index], trainLabelClass2))\n",
        "fig = fig + 1\n",
        "LogisticRegression2D(trainData2, trainLabel2, testData, testLabel, fig, randomSeed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai9WbXTL4NbT",
        "colab_type": "text"
      },
      "source": [
        "### Random over-sampling of minority class for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA7E4sIE4YXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "sampler = RandomOverSampler(random_state=randomSeed)\n",
        "trainData2, trainLabel2 = sampler.fit_resample(trainData, trainLabel)\n",
        "fig = fig + 1\n",
        "LogisticRegression2D(trainData2, trainLabel2, testData, testLabel, fig, randomSeed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7mqj2fVM45CY"
      },
      "source": [
        "### Over-sampling of minority class using SMOTE for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2tNgQ235KBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "sampler = SMOTE(random_state=randomSeed)\n",
        "trainData2, trainLabel2 = sampler.fit_resample(trainData, trainLabel)\n",
        "fig = fig + 1\n",
        "LogisticRegression2D(trainData2, trainLabel2, testData, testLabel, fig, randomSeed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4X_K3Bl5f6S",
        "colab_type": "text"
      },
      "source": [
        "### Classification with weights on classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsvqdSch5rCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classWeight = {0: 1, 1: np.sum(trainLabel == 0)/np.sum(trainLabel == 1)}\n",
        "fig = fig + 1\n",
        "LogisticRegression2D(trainData, trainLabel, testData, testLabel, fig, randomSeed, \n",
        "                     classWeight=classWeight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rk92W1cw67dj",
        "colab_type": "text"
      },
      "source": [
        "# Ensemble Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOpN5xX37Jgb",
        "colab_type": "text"
      },
      "source": [
        "### Generate toy data and visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HRxU5FS7GzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 3000 # Number of samples\n",
        "numFold = 3 # Number of data folds for cross-validation\n",
        "numF = 20 # Total number of features\n",
        "numInfo = 2 # Number of informative features\n",
        "numEstimators = 100\n",
        "randomSeed = 1\n",
        "fig = 0\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "data, label = make_classification(n_samples=N, n_features=numF, n_informative=numInfo, \n",
        "    n_redundant=0, n_repeated=0, n_classes=2, n_clusters_per_class=2, flip_y=0.1, \n",
        "    class_sep=0.3, shift=0.0, scale=1.0, shuffle=False, random_state=randomSeed)\n",
        "\n",
        "fig = fig + 1\n",
        "plt.figure(fig)\n",
        "plt.scatter(data[:, 0], data[:, 1], s=2, c=['red' if label[i] == 0 else 'blue' \n",
        "                                            for i in range(len(label))], alpha=1)\n",
        "plt.title('Whole dataset')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.show()\n",
        "plt.close(fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFyKmOXc8t4n",
        "colab_type": "text"
      },
      "source": [
        "### Partition data into training set and testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-OYprYb81xm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "randID = np.random.RandomState(seed=randomSeed).permutation(N)\n",
        "trainID = randID[:int(N*(numFold-1)/numFold)]\n",
        "testID = randID[int(N*(numFold-1)/numFold):]\n",
        "trainData = data[trainID, :]\n",
        "trainLabel = label[trainID]\n",
        "testData = data[testID, :]\n",
        "testLabel = label[testID]\n",
        "\n",
        "result = np.empty((5, 3))\n",
        "result.fill(np.nan)\n",
        "result = pd.DataFrame(result, index=['RandomForests', 'ExtraTrees', 'AdaBoost', \n",
        "    'lightGBM', 'Stacking'], columns=['Sensitivity', 'Specificity', 'Accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZAt8Xza-lx2",
        "colab_type": "text"
      },
      "source": [
        "### Define a wrapper function for classification and visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJXaSs2r-sFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Classification(trainData, trainLabel, testData, testLabel, numEstimators, clf, fig, randomSeed=1):\n",
        "\n",
        "    if clf == 'RandomForests':\n",
        "        from sklearn.ensemble import RandomForestClassifier\n",
        "        model = RandomForestClassifier(n_estimators=numEstimators, random_state=randomSeed)\n",
        "    if clf == 'lightGBM':\n",
        "        import lightgbm as lgb\n",
        "        model = lgb.LGBMClassifier(n_estimators=numEstimators, random_state=randomSeed)\n",
        "    if clf == 'AdaBoost':\n",
        "        from sklearn.ensemble import AdaBoostClassifier\n",
        "        model = AdaBoostClassifier(n_estimators=numEstimators, random_state=randomSeed)\n",
        "    if clf == 'ExtraTrees':\n",
        "        from sklearn.ensemble import ExtraTreesClassifier\n",
        "        model = ExtraTreesClassifier(n_estimators=numEstimators, random_state=randomSeed)\n",
        "    model.fit(trainData, trainLabel)\n",
        "    pred = model.predict(testData)\n",
        "    predProba = model.predict_proba(testData)\n",
        "    Sensitivity = np.round(np.sum(pred[np.where(testLabel == 1)[0]] == 1) / \n",
        "                           np.sum(testLabel == 1), 3)\n",
        "    Specificity = np.round(np.sum(pred[np.where(testLabel == 0)[0]] == 0) / \n",
        "                           np.sum(testLabel == 0), 3)\n",
        "    Accuracy = np.round(np.sum(pred == testLabel) / len(testLabel), 3)\n",
        "    \n",
        "    plt.figure(fig)\n",
        "    plt.scatter(testData[:, 0], testData[:, 1], s=2, c=['red' if pred[i] == 0 else \n",
        "        'blue' for i in range(len(pred))], alpha=1)\n",
        "    plt.title('Sensitivity = ' + str(Sensitivity) + ', Specificity = ' + \n",
        "              str(Specificity) + ', Accuracy = ' + str(Accuracy))\n",
        "    plt.xlabel('Feature 1')\n",
        "    plt.ylabel('Feature 2')\n",
        "    plt.show()\n",
        "    plt.close(fig)\n",
        "    \n",
        "    return Sensitivity, Specificity, Accuracy, predProba"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJ7deudf88gS",
        "colab_type": "text"
      },
      "source": [
        "### Random forests classification and visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A35wH_RM9HNS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = fig + 1\n",
        "Sensitivity, Specificity, Accuracy, predRF = Classification(trainData, trainLabel, testData, \n",
        "    testLabel, numEstimators, 'RandomForests', fig, randomSeed)\n",
        "result.loc['RandomForests', 'Sensitivity'] = Sensitivity\n",
        "result.loc['RandomForests', 'Specificity'] = Specificity\n",
        "result.loc['RandomForests', 'Accuracy'] = Accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCYpy1nN9uEN",
        "colab_type": "text"
      },
      "source": [
        "### Extra trees classification and visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvmx059c92BF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = fig + 1\n",
        "Sensitivity, Specificity, Accuracy, predET = Classification(trainData, trainLabel, testData, \n",
        "    testLabel, numEstimators, 'ExtraTrees', fig, randomSeed)\n",
        "result.loc['ExtraTrees', 'Sensitivity'] = Sensitivity\n",
        "result.loc['ExtraTrees', 'Specificity'] = Specificity\n",
        "result.loc['ExtraTrees', 'Accuracy'] = Accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAsAk0Onabat",
        "colab_type": "text"
      },
      "source": [
        "### AdaBoost classification and visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq2QXYZ9apOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = fig + 1\n",
        "Sensitivity, Specificity, Accuracy, predAB = Classification(trainData, trainLabel, testData, \n",
        "    testLabel, numEstimators, 'AdaBoost', fig, randomSeed)\n",
        "result.loc['AdaBoost', 'Sensitivity'] = Sensitivity\n",
        "result.loc['AdaBoost', 'Specificity'] = Specificity\n",
        "result.loc['AdaBoost', 'Accuracy'] = Accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em2OpEpBa7iX",
        "colab_type": "text"
      },
      "source": [
        "### LightGBM classification and visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7kGhmWObUAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = fig + 1\n",
        "Sensitivity, Specificity, Accuracy, predGBM = Classification(trainData, trainLabel, testData, \n",
        "    testLabel, numEstimators, 'lightGBM', fig, randomSeed)\n",
        "result.loc['lightGBM', 'Sensitivity'] = Sensitivity\n",
        "result.loc['lightGBM', 'Specificity'] = Specificity\n",
        "result.loc['lightGBM', 'Accuracy'] = Accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdCRHVifbk5j",
        "colab_type": "text"
      },
      "source": [
        "### Define a function for generating meta training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkCM7zixcTaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def GenerateMetaTrainingData(data, label, numFold, numEstimators, \n",
        "    clf=['RandomForests', 'lightGBM', 'AdaBoost', 'ExtraTrees'], randomSeed=1):\n",
        "  \n",
        "    import lightgbm as lgb\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.ensemble import ExtraTreesClassifier\n",
        "    from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "    numS = data.shape[0]\n",
        "    numC = len(clf)\n",
        "    trainMeta = np.empty((numS, numC))\n",
        "    randID = np.random.RandomState(seed=randomSeed).permutation(numS)\n",
        "\n",
        "    # Generate sample IDs for cross-validation\n",
        "    sFold = []\n",
        "    foldSize = np.ceil(numS/numFold)\n",
        "    for n in range(numFold):\n",
        "        startID = np.int(foldSize*n)\n",
        "        endID = np.int(np.min([foldSize*(n + 1), numS]))\n",
        "        sFold.append({'trainID': randID[np.setdiff1d(range(numS), range(startID, \n",
        "            endID))], 'testID': randID[startID:endID]})\n",
        "\n",
        "    for n in range(numFold):\n",
        "        for c in range(len(clf)):\n",
        "            if clf[c] == 'RandomForests':\n",
        "                model = RandomForestClassifier(n_estimators=numEstimators, random_state=randomSeed)\n",
        "            if clf[c] == 'lightGBM':\n",
        "                model = lgb.LGBMClassifier(n_estimators=numEstimators, random_state=randomSeed)\n",
        "            if clf[c] == 'AdaBoost':\n",
        "                model = AdaBoostClassifier(n_estimators=numEstimators, random_state=randomSeed)\n",
        "            if clf[c] == 'ExtraTrees':\n",
        "                model = ExtraTreesClassifier(n_estimators=numEstimators, random_state=randomSeed)\n",
        "            model.fit(data[sFold[n]['trainID'], :], label[sFold[n]['trainID']])\n",
        "            trainMeta[sFold[n]['testID'], c] = model.predict_proba(data[sFold[n]['testID'], :])[:, 0]\n",
        "\n",
        "    return trainMeta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2KLxWLQfPRH",
        "colab_type": "text"
      },
      "source": [
        "### Generate and standardize meta training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLqoD8zbffBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainMeta = GenerateMetaTrainingData(trainData, trainLabel, numFold, numEstimators,\n",
        "    clf=['RandomForests', 'lightGBM', 'AdaBoost', 'ExtraTrees'], randomSeed=randomSeed)\n",
        "\n",
        "testMeta = np.empty((predRF.shape[0], 4))\n",
        "testMeta[:, 0] = predRF[:, 0]\n",
        "testMeta[:, 1] = predGBM[:, 0]\n",
        "testMeta[:, 2] = predAB[:, 0]\n",
        "testMeta[:, 3] = predET[:, 0]\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "temp = scaler.fit_transform(np.vstack((trainMeta, testMeta)))\n",
        "trainMeta = temp[:trainMeta.shape[0], :]\n",
        "testMeta = temp[trainMeta.shape[0]:, :]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6z1Uv9ugV-X",
        "colab_type": "text"
      },
      "source": [
        "### Train logistic regression as the meta classifier to produce final prediction outcome"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVYmeoFKgm3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "LR = LogisticRegression(random_state=randomSeed, solver='lbfgs')\n",
        "LR.fit(trainMeta, trainLabel)\n",
        "pred = LR.predict(testMeta)\n",
        "result.loc['Stacking', 'Sensitivity'] = np.round(np.sum(pred[np.where(testLabel \n",
        "    == 1)[0]] == 1) / np.sum(testLabel == 1), 3)\n",
        "result.loc['Stacking', 'Specificity'] = np.round(np.sum(pred[np.where(testLabel \n",
        "    == 0)[0]] == 0) / np.sum(testLabel == 0), 3)\n",
        "result.loc['Stacking', 'Accuracy'] = np.round(np.sum(pred == testLabel) / \n",
        "    len(testLabel), 3)\n",
        "\n",
        "fig = fig + 1\n",
        "plt.figure(fig)\n",
        "plt.scatter(testData[:, 0], testData[:, 1], s=2, c=['red' if pred[i] == 0 \n",
        "    else 'blue' for i in range(len(pred))], alpha=1)\n",
        "plt.title('Sensitivity = ' + str(result.loc['Stacking', 'Sensitivity']) + \n",
        "          ', Specificity = ' + str(result.loc['Stacking', 'Specificity']) + \n",
        "          ', Accuracy = ' + str(result.loc['Stacking', 'Accuracy']))\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.show()\n",
        "plt.close(fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNRNQvNAk4xh",
        "colab_type": "text"
      },
      "source": [
        "### Summary of prediction performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSYsO3YZlAPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}