{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Digit Classification with Keras\n",
    "The [MNIST dataset](https://en.wikipedia.org/wiki/MNIST_database) is a database of hand-written digits matched with their actual value that has been exceedingly well used by the machine learning community. It is large and easily describable, which makes it a great example for learning to use convolutional neural networks.\n",
    "\n",
    "This exercise draws extensively from [Keras tutorials](https://github.com/keras-team/keras/blob/master/examples).\n",
    "\n",
    "This notebook contains many sections that are filled out for you and many that you will need to fill out to complete the exercise (marked in <font color='red'>RED</font>). You are finished when \"Restarting and Run All Cells\" executes the entire notebook without producing any errors. Do not remove assert statements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from keras import optimizers as opt\n",
    "from keras.datasets import mnist\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "from time import perf_counter\n",
    "from math import isclose\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import keras\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some maintenance things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "The MNIST data is easily accessible from Keras and needs a little bit of preprocessing before it is useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(f'Input data shape: {x_train.shape}')\n",
    "print(f'Output data shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is returned as 60000 28x28 images.\n",
    "Depending on the backend for Keras, we need to turn these into either 28x28x1 or 1x28x28 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'New data shape: {input_shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data are also integer values between 0 and 255. We need them as single-precision floating point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are integers between 0 and 9. \n",
    "As we are treating digits as simple categories and not considering the ordering between them, we need to one-hot encode the data.\n",
    "(Recall doing this in the last exercise for the categorical input variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Output for entry 0: {y_train[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'New output for entry 0: {y_train[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'New output data shape: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we are now ready to go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Tutorial: Classification Models and Keras\n",
    "All of our previous examples have used regression models.\n",
    "So, some brief lessons on classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring Classification Models\n",
    "There are [many ways to rate the quality of classification](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics), each with their own benefits.\n",
    "\n",
    "For example, the [False Positive Rate (FPR)](https://en.wikipedia.org/wiki/False_positive_rate) scores how often your model yields an incorrect prediction.\n",
    "FPR is good for metrics where the cost of reacting to an incorrect positive is high, but would be a poor choice when missing a detection is bad (e.g., fast screening for disease).\n",
    "\n",
    "Our digit classification challenge is simple. We just want to get as many digits correct as possible.\n",
    "Getting more \"0\"s correct is just as important as getting any other digit.\n",
    "So, for that reason, we will use accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score([0, 1, 0], [0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is great for humans to understand the quality of a model but has a big issue if it were used as a loss function: discontinuous derivates.\n",
    "\n",
    "Classification models produce probabilities of an entry (e.g., an image) being in a certain category (e.g., a certain digit) and accuracy scores do not use them well.\n",
    "Small changes in predictions for the probabilities of each entry can lead to step changes in the accuracy.\n",
    "Step changes lead to infinite gradients, which causes problems with gradient decent optimization.\n",
    "\n",
    "So, instead, we use \"log-loss\" or \"categorical cross entry.\" \n",
    "Log-loss has smooth derivates for all changes in probability, which is good for neural network optimization.\n",
    "It also has a nice trait that predictions that are not just correct but more confidently-correct are given better (lower) scores.\n",
    "Ther are other classification quality metrics that have these properties, but log-loss is what we will use today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert log_loss([0], [[0.6, 0.4]], labels=[0, 1]) > log_loss([0], [[0.7, 0.3]], labels=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Layers and Keras\n",
    "As you will see, special activation functions are needed for performing classification in Keras.\n",
    "\n",
    "- `softmax` is a good choice for multi-class (i.e., more than 2 classes) classification problem. \n",
    "  It takes a vector of real numbers in and returns them in the range [0, 1] with a sum of 1, which looks like a probability distribution.\n",
    "- `sigmoid` is a good choice for binary classification (only 2 classes) as, like `softmax`, it produces a number on [0, 1]. But, it only takes a single number as input, which makes it simpler than `softmax` to evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustrating `softmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([layers.Dense(10, activation='softmax', input_shape=(2,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(np.array([[-1, 2]]))  # Not trained, so the outputs are meaningless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Note that all numebrs are between 0 and 1:', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('And they have a sum of 1 (or close to it): ', output.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Part 1: Train a Fully Connected Neural Network</font>\n",
    "Use what you learned from Excerise 2 to train a regular, fully-connected neural network with two hidden layers of 512 units.\n",
    "\n",
    "**HINT**: You will need to use the `softmax` activation in the last layer only.\n",
    "\n",
    "**HINT**: You will need a [Flatten](https://keras.io/layers/core/#flatten) layer to shape the data from a 28x28x1 array to a 1D vector (see below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.predict(x_train[:1]).shape == (1, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>At present the model just flattens the images. You need to add the rest</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.count_params() == 669706 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Compile and train the model using the RMSProp optimizer</font>\n",
    "\n",
    "**HINT**: Use an appropriate [loss function](https://keras.io/losses/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Now, fit the model with enough epochs for it to converge and a reasonable batch size</font>\n",
    "\n",
    "**HINT**: How can you prevent overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_accuracy = accuracy_score(model.predict_classes(x_test), y_test)\n",
    "print(f'Accuracy on hold-out set: {dnn_accuracy * 100 : .2f}%')\n",
    "assert dnn_accuracy > 0.975"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Part 2: Make a CNN</font>\n",
    "Our next step is to use a Convolutional Neural Network. \n",
    "\n",
    "The simple \"convolution\" plus \"pooling\" example in lecture is indeed simpler than the common types of CNNs seen in practice.\n",
    "We did not have a last layer that performs the actual classification, and used a \"max pool\" that reduced the image down to a single value.\n",
    "Typically, we want multiple layers of convolutions to learn very complex filters and do not want to reduce an image down to a single pixel between each stage.\n",
    "\n",
    "Your task is to train network from [Muhammad Rizwan's tutorial](https://engmrk.com/convolutional-neural-network-3/) with ReLU activation functions: \n",
    "\n",
    "<img width=50% src=\"https://engmrk.com/wp-content/uploads/2018/09/Image-Architecture-of-Convolutional-Neural-Network.png\"/>\n",
    "\n",
    "**HINT**: Read the Keras documentation for [Convolutional](https://keras.io/layers/convolutional/) and [Pooling](https://keras.io/layers/pooling/) layers.\n",
    "\n",
    "**HINT**: Your input shape is the shape of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Make the model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.count_params() == 1111946"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Train it</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_accuracy = accuracy_score(model.predict_classes(x_test), y_test)\n",
    "print(f'Accuracy on hold-out set: {cnn_accuracy * 100 : .2f}%')\n",
    "assert cnn_accuracy > 0.985"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy should be higher than your fully-connected nueral network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
