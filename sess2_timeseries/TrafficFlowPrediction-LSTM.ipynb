{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers.recurrent import SimpleRNN, LSTM, GRU\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(train, test, lags):\n",
    "    \"\"\"Process data\n",
    "    Reshape and split train\\test data.\n",
    "\n",
    "    # Arguments\n",
    "        train: String, name of .csv train file.\n",
    "        test: String, name of .csv test file.\n",
    "        lags: integer, time lag.\n",
    "    # Returns\n",
    "        X_train: ndarray.\n",
    "        y_train: ndarray.\n",
    "        X_test: ndarray.\n",
    "        y_test: ndarray.\n",
    "        scaler: StandardScaler.\n",
    "    \"\"\"\n",
    "    attr = 'Lane 1 Flow (Veh/5 Minutes)'\n",
    "    df1 = pd.read_csv(train, encoding='utf-8').fillna(0)\n",
    "    df2 = pd.read_csv(test, encoding='utf-8').fillna(0)\n",
    "\n",
    "    # scaler = StandardScaler().fit(df1[attr].values)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(df1[attr].values.reshape(-1, 1))\n",
    "    flow1 = scaler.transform(df1[attr].values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "    flow2 = scaler.transform(df2[attr].values.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "\n",
    "    train, test = [], []\n",
    "    for i in range(lags, len(flow1)):\n",
    "        train.append(flow1[i - lags: i + 1])\n",
    "    for i in range(lags, len(flow2)):\n",
    "        test.append(flow2[i - lags: i + 1])\n",
    "\n",
    "    train = np.array(train)\n",
    "    test = np.array(test)\n",
    "    np.random.shuffle(train)\n",
    "\n",
    "    X_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    X_test = test[:, :-1]\n",
    "    y_test = test[:, -1]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train the NN model.\n",
    "\"\"\"\n",
    "def get_rnn(units):\n",
    "    \"\"\"LSTM(Long Short-Term Memory)\n",
    "    Build LSTM Model.\n",
    "\n",
    "    # Arguments\n",
    "        units: List(int), number of input, output and hidden units.\n",
    "    # Returns\n",
    "        model: Model, nn model.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(units[1], input_shape=(units[0], 1), return_sequences=True))\n",
    "    model.add(SimpleRNN(units[2]))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units[3], activation='sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_lstm(units):\n",
    "    \"\"\"LSTM(Long Short-Term Memory)\n",
    "    Build LSTM Model.\n",
    "\n",
    "    # Arguments\n",
    "        units: List(int), number of input, output and hidden units.\n",
    "    # Returns\n",
    "        model: Model, nn model.\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units[1], input_shape=(units[0], 1), return_sequences=True))\n",
    "    model.add(LSTM(units[2]))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units[3], activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, name, config):\n",
    "    \"\"\"train\n",
    "    train a single model.\n",
    "\n",
    "    # Arguments\n",
    "        model: Model, NN model to train.\n",
    "        X_train: ndarray(number, lags), Input data for train.\n",
    "        y_train: ndarray(number, ), result data for train.\n",
    "        name: String, name of model.\n",
    "        config: Dict, parameter for train.\n",
    "    \"\"\"\n",
    "\n",
    "    model.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=['mse'])\n",
    "    model.summary()\n",
    "    # early = EarlyStopping(monitor='val_loss', patience=30, verbose=0, mode='auto')\n",
    "    hist = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=config[\"batch\"],\n",
    "        epochs=config[\"epochs\"],\n",
    "        validation_split=0.05)\n",
    "\n",
    "    folder = 'model/'\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    model.save('model/' + name + '.h5')\n",
    "    df = pd.DataFrame.from_dict(hist.history)\n",
    "    df.to_csv('model/' + name + ' loss.csv', encoding='utf-8', index=False)\n",
    "\n",
    "    return hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lag = 12\n",
    "config = {\"batch\": 256, \"epochs\": 10}\n",
    "file1 = 'repo/sess2_timeseries/data/train.csv'\n",
    "file2 = 'repo/sess2_timeseries/data/test.csv'\n",
    "X_train, y_train, _, _, _ = process_data(file1, file2, lag)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_rnn([12, 64, 64, 1])\n",
    "history = train_model(m, X_train, y_train, 'rnn', config)\n",
    "\n",
    "plt.figure(figsize=(21, 11))\n",
    "plt.plot(history.history['loss'], linewidth=4)\n",
    "plt.plot(history.history['val_loss'], linewidth=4)\n",
    "plt.title('model loss', fontsize=40)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.xticks(fontsize=40)\n",
    "plt.ylabel('loss', fontsize=40)\n",
    "plt.xlabel('epoch', fontsize=40)\n",
    "plt.legend(['train', 'val'], loc='upper left', fontsize=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_lstm([12, 64, 64, 1])\n",
    "history = train_model(m, X_train, y_train, 'lstm', config)\n",
    "\n",
    "plt.figure(figsize=(21, 11))\n",
    "plt.plot(history.history['loss'], linewidth=4)\n",
    "plt.plot(history.history['val_loss'], linewidth=4)\n",
    "plt.title('model loss', fontsize=40)\n",
    "plt.yticks(fontsize=40)\n",
    "plt.xticks(fontsize=40)\n",
    "plt.ylabel('loss', fontsize=40)\n",
    "plt.xlabel('epoch', fontsize=40)\n",
    "plt.legend(['train', 'val'], loc='upper left', fontsize=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Traffic Flow Prediction with Neural Networks(SAEs、LSTM、GRU).\n",
    "\"\"\"\n",
    "def MAPE(y_true, y_pred):\n",
    "    \"\"\"Mean Absolute Percentage Error\n",
    "    Calculate the mape.\n",
    "\n",
    "    # Arguments\n",
    "        y_true: List/ndarray, ture data.\n",
    "        y_pred: List/ndarray, predicted data.\n",
    "    # Returns\n",
    "        mape: Double, result data for train.\n",
    "    \"\"\"\n",
    "\n",
    "    y = [x for x in y_true if x > 0]\n",
    "    y_pred = [y_pred[i] for i in range(len(y_true)) if y_true[i] > 0]\n",
    "\n",
    "    num = len(y_pred)\n",
    "    sums = 0\n",
    "\n",
    "    for i in range(num):\n",
    "        tmp = abs(y[i] - y_pred[i]) / y[i]\n",
    "        sums += tmp\n",
    "\n",
    "    mape = sums * (100 / num)\n",
    "\n",
    "    return mape\n",
    "\n",
    "\n",
    "def eva_regress(y_true, y_pred):\n",
    "    \"\"\"Evaluation\n",
    "    evaluate the predicted resul.\n",
    "\n",
    "    # Arguments\n",
    "        y_true: List/ndarray, ture data.\n",
    "        y_pred: List/ndarray, predicted data.\n",
    "    \"\"\"\n",
    "\n",
    "    mape = MAPE(y_true, y_pred)\n",
    "    vs = metrics.explained_variance_score(y_true, y_pred)\n",
    "    mae = metrics.mean_absolute_error(y_true, y_pred)\n",
    "    mse = metrics.mean_squared_error(y_true, y_pred)\n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "    print('explained_variance_score:%f' % vs)\n",
    "    print('mape:%f%%' % mape)\n",
    "    print('mae:%f' % mae)\n",
    "    print('mse:%f' % mse)\n",
    "    print('rmse:%f' % math.sqrt(mse))\n",
    "    print('r2:%f' % r2)\n",
    "\n",
    "\n",
    "def plot_results(y_true, y_preds, names):\n",
    "    \"\"\"Plot\n",
    "    Plot the true data and predicted data.\n",
    "\n",
    "    # Arguments\n",
    "        y_true: List/ndarray, ture data.\n",
    "        y_pred: List/ndarray, predicted data.\n",
    "        names: List, Method names.\n",
    "    \"\"\"\n",
    "    d = '2016-3-4 00:00'\n",
    "    x = pd.date_range(d, periods=288, freq='5min')\n",
    "\n",
    "    fig = plt.figure(figsize=(21, 11))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.plot(x, y_true, label='True Data', linewidth=4)\n",
    "    for name, y_pred in zip(names, y_preds):\n",
    "        ax.plot(x, y_pred, label=name, linewidth=4)\n",
    "\n",
    "    plt.legend(prop={'size': 40})\n",
    "    plt.yticks(fontsize=40)\n",
    "    plt.xticks(fontsize=40)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Time of Day', fontsize=50)\n",
    "    plt.ylabel('Flow', fontsize=50)\n",
    "\n",
    "    date_format = mpl.dates.DateFormatter(\"%H:%M\")\n",
    "    ax.xaxis.set_major_formatter(date_format)\n",
    "    fig.autofmt_xdate()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = load_model('model/rnn.h5')\n",
    "lstm = load_model('model/lstm.h5')\n",
    "models = [rnn,lstm]\n",
    "names = ['RNN','LSTM']\n",
    "\n",
    "lag = 12\n",
    "file1 = 'repo/sess2_timeseries/data/train.csv'\n",
    "file2 = 'repo/sess2_timeseries/data/test.csv'\n",
    "_, _, X_test, y_test, scaler = process_data(file1, file2, lag)\n",
    "y_test = scaler.inverse_transform(y_test.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "\n",
    "y_preds = []\n",
    "for name, model in zip(names, models):\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    plot_model(model, show_shapes=True)\n",
    "    predicted = model.predict(X_test)\n",
    "    predicted = scaler.inverse_transform(predicted.reshape(-1, 1)).reshape(1, -1)[0]\n",
    "    y_preds.append(predicted[:288])\n",
    "    eva_regress(y_test, predicted)\n",
    "\n",
    "plot_results(y_test[: 288], y_preds, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[: 288].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
