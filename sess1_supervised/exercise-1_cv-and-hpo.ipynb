{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Cross Validation and Hyperparameter Optimization\n",
    "In this exercise, you will learn how to perform cross-validation and to optimize machine learning models using [scikit-learn](https://scikit-learn.org/stable/). \n",
    "\n",
    "This notebook contains many sections that are filled out for you and many that you will need to fill out to complete the exercise (marked in <font color='red'>RED</font>). You are finished when \"Restarting and Run All Cells\" executes the entire notebook without producing any errors. Do not remove assert statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit, cross_validate\n",
    "from sklearn.linear_model.coordinate_descent import ConvergenceWarning\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import scorer\n",
    "from math import isclose\n",
    "import numpy as np\n",
    "import warnings\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Perform Cross-Validation on 1-D Model\n",
    "In this part of the notebook, you will show how to test the generalizability of machine learning models with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Set up the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we make the example function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-4, 4, 32)[:, None]  # [:, None] turns a 1D array into a 2D array with 1 column\n",
    "y = X ** 3 / 12 + 0.25 * (X - 1) ** 2 - 0.5 * X + 1 + np.random.normal(scale=0.4, size=X.shape, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pro Tip*: The use of [Numpy](https://www.numpy.org/) allows us to perform array operations, which are faster than Python loops and make your code easier to read/maintain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(X, y)\n",
    "\n",
    "ax.set_xlabel('$X$')\n",
    "ax.set_ylabel('$y$')\n",
    "fig.set_size_inches(3.5, 2.5)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the data has a roughly-cubic shape, but the noise obscures it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set up the Model\n",
    "We are going to use a polynomial regression model to fit this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=8)),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "poly_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is built using the [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) tool from scikit-learn. \n",
    "Pipeline models that are composed of multiple steps that are performed sequentially when fitting or evaluating the a model.\n",
    "In our case, these are:\n",
    "1. [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html): Combine the initial list of features into terms of polynomial\n",
    "2. [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html): Fit or evaluate a linear regression model\n",
    "\n",
    "*ProTip*: Use Pipeline models to avoid having to keep track of multiple steps. Pipeline models behave as normal scikit-learn ML models, so you can use them as you would use any other model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Tutorial: Setting model parameters\n",
    "The `set_params` function of a scikit-learn model defines the parameters of the model. \n",
    "For Pipelines, the names of the settings are `[step name]__[param name]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_model.set_params(poly__degree=7)  # You can set the variables with `set_params`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Tutorial: `Fit` and `Predict` using Scikit-Learn\n",
    "The first thing you will need to know is how to train and evaluate a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit` method a scikit-learn model trains the model using provided training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict operation evaluates the trained model using the learned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_plot = np.linspace(-4, 4, 256)[:, None]  # Points to use for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Make the predicions with the model\n",
    "y_pred = poly_model.predict(X_plot)\n",
    "\n",
    "ax.scatter(X, y)\n",
    "ax.plot(X_plot, y_pred, 'k--')\n",
    "\n",
    "ax.set_xlabel('$X$')\n",
    "ax.set_ylabel('$y$')\n",
    "fig.set_size_inches(3.5, 2.5)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the model seems to fit the data well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Step 3: Perform Cross-Validation</font>\n",
    "Now, it is your turn to perform cross valiadtion of the model using cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Tutorial: Cross-validation in Scikit-Learn\n",
    "Scikit-Learn has [many tools for simplifying performing cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html). Here, we are going to teach you how to use the [`cross_validate` function](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html), which performs CV in one line of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function takes your model, training data, and a few settings about how to you want to perform the test (e.g., cross-validation scheme, scoring metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(poly_model, X, y, cv=4, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and returns a dictionary of the performance scores and fit times. Note that the values for mean absolute error are negative, as this follows a convention that \"the maximum score corrresponds to maximum performance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Task 1: Run cross-validation</font>\n",
    "Run 8-fold cross validation on a polynomial model of degree 5 and return the correlation coefficient\n",
    "\n",
    "**HINT**: See the links to the scikit-learn documentation in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isclose(cv_results['test_score'].mean(), -2.915306, abs_tol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> Task 2: Show performance is better with 3 degrees than 5 degrees</font>\n",
    "At least with the correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree5_score = cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree3_score = cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert degree3_score > degree5_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Hyperparameter Optimization\n",
    "Now, we show how to tune the performance of a model using hyper parameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Tutorial: GridSearchCV\n",
    "[GridSearchCV](https://scikit-learn.org/0.17/modules/generated/sklearn.grid_search.GridSearchCV.html) is a tool that automates running cross-validation for models with different parameters, and telling you which is the best.\n",
    "\n",
    "We are going to show you using it for determining the optimal degree for the polynomial in question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You create the GridSearchCV by defining the model to be optimized and the parameters to be varied. \n",
    "There are other optional parameters about the type of cross-validation method, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(poly_model, param_grid={'poly__degree': range(10)}, cv=8, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the `fit` method performs the tests for all models defined in the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are stored in attributes of the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the model determined the best parameters to be 3. \n",
    "\n",
    "You can access the best model as another class attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Make the predicions with the model\n",
    "y_pred = best_model.predict(X_plot)\n",
    "\n",
    "ax.scatter(X, y)\n",
    "ax.plot(X_plot, y_pred, 'k--')\n",
    "\n",
    "ax.set_xlabel('$X$')\n",
    "ax.set_ylabel('$y$')\n",
    "fig.set_size_inches(3.5, 2.5)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this model fits our data very well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'>Task 2: Fit a LASSO model</font>\n",
    "Your task is to use GridSearchCV to determine the optimal penalty parameter for a LASSO model.\n",
    "[LASSO](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) is a modelling technique where you apply a penalty to a linear regression model equal to a constant times the sum of the absolute values of the coefficients, which is called $L_1$ Regularization.\n",
    "Larger values of the constant value (called `alpha` in scikit-learn) lead to poorer fitting of the training set at the potential benefit of less overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=30)), ## Do not adjust the degree this time!\n",
    "    ('lasso', Lasso(normalize=True))  # normalize=True removes the mean from the data before fitting, gives better results\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HINT**: Use `np.logspace` to generate alphas across many orders of magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pro Tip*: Hyperparameter optimization tends to produce warnings. Use Python's [warning module](https://docs.python.org/3/library/warnings.html) to keep your notebooks legible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=ConvergenceWarning)\n",
    "    gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert gs.best_score_ > -0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Make the predicions with the model\n",
    "y_pred = best_model.predict(X_plot)\n",
    "\n",
    "ax.scatter(X, y)\n",
    "ax.plot(X_plot, y_pred, 'k--')\n",
    "\n",
    "ax.set_xlabel('$X$')\n",
    "ax.set_ylabel('$y$')\n",
    "fig.set_size_inches(3.5, 2.5)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finding*: Not quite as pretty as limiting complexity, but the score is still reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
